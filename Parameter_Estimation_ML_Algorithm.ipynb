{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b15a13a",
   "metadata": {},
   "source": [
    "# Using ML for paramter estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3f91eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sl\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "np.random.seed(1333)\n",
    "\n",
    "\"\"\"Loading the Data\"\"\"\n",
    "\n",
    "dir       = 'data/'\n",
    "file_name = 'grid1_zheb51fo.xlsx'\n",
    "UX1       = pd.read_excel(dir+file_name, sheet_name='UX1_Index')\n",
    "UX2       = pd.read_excel(dir+file_name, sheet_name='UX2_Index')\n",
    "UX1       = UX1.set_index('Date')\n",
    "UX2       = UX2.set_index('Date')\n",
    "UX1.sort_index(inplace=True)\n",
    "UX2.sort_index(inplace=True)\n",
    "dataset = np.array(UX1.PX_LAST)\n",
    "dataset = dataset[4:]              #we drop 4 data for simpler illustratoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693af0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Specifying the Input & Output (Labels)\"\"\"\n",
    "\n",
    "n=0     #Looking at n previous days to estimate paramteres\n",
    "X=np.array([[dataset[j] for j in range(i, i+n+1)] for i in range(len(dataset) - n)])\n",
    "Y=np.array([dataset[i+n] for i in range(len(dataset) - n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a680e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting Data into Train and Test set\"\"\"\n",
    "\n",
    "m_training= 2000\n",
    "m_test= 1000\n",
    "\n",
    "X_training=X[:m_training]\n",
    "Y_training=Y[:m_training]\n",
    "\n",
    "X_test=X[m_training:]\n",
    "Y_test=Y[m_training:]\n",
    "\n",
    "#for the case of n=0\n",
    "X_training= np.ravel(X_training)  \n",
    "X_test    = np.ravel(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4836c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing NaN values:\n",
    "nan_array = np.isnan(X_test)\n",
    "not_nan_array = ~ nan_array\n",
    "X_test = X_test[not_nan_array]\n",
    "\n",
    "nan_array = np.isnan(Y_test)\n",
    "not_nan_array = ~ nan_array\n",
    "Y_test = Y_test[not_nan_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0fd5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Building the Hypothesis\"\"\"\n",
    "\n",
    "def heston_pde_milstein(V0, k, theta, rho, sigma):\n",
    "    WT  = np.sqrt( 1 ) * np.random.multivariate_normal( np.array( [0,  0] ), np.array( [[1, rho], [rho, 1]] ), size=1)\n",
    "    V1 = np.abs(V0+ k * (theta - V0) * 1 + sigma * np.sqrt(V0) * WT[:, 1] + .25 * sigma**2 * (WT[:,1]**2 - 1))\n",
    "    return V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae600854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Building the Loss Function\"\"\"\n",
    "\n",
    "#The difference between real label and the predicted one to the power of 2\n",
    "#l = (heston_pde_milstein(X_training[i], r, k, theta, rho, sigma) - Y_training[i])**2\n",
    "\n",
    "m=len(X_training)  #Training set size\n",
    "# k: x[0], theta:x[1], rho:x[2], sigma:x[3]\n",
    "\n",
    "def Ls(X):\n",
    "    def heston_inner_func(i):   #calculates the predicted lable for each training sample\n",
    "        WT  = np.random.multivariate_normal(np.array([0, 0]), np.array([[1, X[2]], [X[2], 1]]), size=1)\n",
    "        V1 =  np.abs(X_training[i] + X[0] * (X[0] - X_training[i]) * 1 + \n",
    "                     X[3] * np.sqrt(X_training[i]) * WT[:, 1] + .25 * X[3]**2 * (WT[:,1]**2 - 1))\n",
    "        return V1\n",
    "    Ls = (1/m) * np.sum(np.array([(heston_inner_func(i) - Y_training[i])**2 for i in range(m)]))\n",
    "    return Ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5cf629d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-602f0807d17a>:11: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  WT  = np.random.multivariate_normal(np.array([0, 0]), np.array([[1, X[2]], [X[2], 1]]), size=1)\n",
      "<ipython-input-6-602f0807d17a>:11: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  WT  = np.random.multivariate_normal(np.array([0, 0]), np.array([[1, X[2]], [X[2], 1]]), size=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ERM: Empirical Risk Minimization\"\"\"\n",
    "\n",
    "result = minimize(Ls, (2,2,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ecd2991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paramteres: [2.00000025 1.99999996 2.00000009 2.00000002]\n",
      "Minimum Ls: 84.16463517753044\n"
     ]
    }
   ],
   "source": [
    "best_params = result.x\n",
    "print(\"Best Paramteres:\", best_params)\n",
    "print(\"Minimum Ls:\", result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "371890d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112.51648225044893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-92f9a5195994>:4: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  WT  = np.sqrt( 1 ) * np.random.multivariate_normal( np.array( [0,  0] ), np.array( [[1, rho], [rho, 1]] ), size=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Evaluating the model on test Set\"\"\"\n",
    "\n",
    "k, theta, rho, sigma = best_params[0], best_params[1], best_params[2], best_params[3]\n",
    "Y_pred = np.array([heston_pde_milstein(X_test[i], k, theta, rho, sigma) for i in range(len(X_test))])\n",
    "Y_pred = np.ravel(Y_pred)\n",
    "\n",
    "#True Error\n",
    "Ld =  (1/len(Y_test)) * np.sum((Y_pred - Y_test)**2)\n",
    "print(Ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4904a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred_train = np.array([heston_pde_milstein(X_training[i], k, theta, rho, sigma) for i in range(len(X_training))])\n",
    "# L =  (1/m) * np.sum((Y_pred_train - Y_training)**2)\n",
    "# print(L)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
