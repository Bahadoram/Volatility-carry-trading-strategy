{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b15a13a",
   "metadata": {},
   "source": [
    "# Using ML for paramter estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3f91eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sl\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\"\"\"Loading the Data\"\"\"\n",
    "\n",
    "dir       = 'data/'\n",
    "file_name = 'grid1_zheb51fo.xlsx'\n",
    "UX1       = pd.read_excel(dir+file_name, sheet_name='UX1_Index')\n",
    "UX2       = pd.read_excel(dir+file_name, sheet_name='UX2_Index')\n",
    "UX1       = UX1.set_index('Date')\n",
    "UX2       = UX2.set_index('Date')\n",
    "UX1.dropna(subset = [\"PX_LAST\"], inplace=True)   #Getting rid of NaN values\n",
    "UX2.dropna(subset = [\"PX_LAST\"], inplace=True)\n",
    "UX1.sort_index(inplace=True)\n",
    "UX2.sort_index(inplace=True)\n",
    "dataset = np.array(UX1.PX_LAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "693af0a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24.85, 24.45, 23.55], [24.45, 23.55, 23.15], [23.55, 23.15, 22.55], [23.15, 22.55, 22.25], [22.55, 22.25, 22.8], [22.25, 22.8, 22.5], [22.8, 22.5, 22.0], [22.5, 22.0, 22.55], [22.0, 22.55, 21.55], [22.55, 21.55, 21.4]]\n",
      "\n",
      "\n",
      "[23.15, 22.55, 22.25, 22.8, 22.5, 22.0, 22.55, 21.55, 21.4, 22.65]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Specifying the Input & Output (Labels)\"\"\"\n",
    "\n",
    "n=2     #Looking at n previous days to estimate paramteres + today's volatility\n",
    "X= [[dataset[j] for j in range(i, i+n+1)] for i in range(len(dataset) - n - 1)]\n",
    "Y= [dataset[i+n+1] for i in range(len(dataset) - n -1)]\n",
    "\n",
    "# Putting more emphasis on today's data:\n",
    "\n",
    "emphasis = 0    #repearing today's value emphasis times\n",
    "for i in range(len(X)):\n",
    "    for j in range(emphasis-1):\n",
    "        X[i].append(X[i][-1])        \n",
    "        \n",
    "print(X[:10])\n",
    "print(\"\\n\")\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a680e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting Data into Train and Test set\"\"\"\n",
    "\n",
    "m_training= 2000\n",
    "m_test= 1000\n",
    "\n",
    "X_training=X[ :m_training  ]\n",
    "Y_training=Y[1:m_training+1]   #The labels are shifted 1 to the right since they are tomorrow's value\n",
    "\n",
    "X_test=X[m_training:m_test]\n",
    "Y_test=Y[m_training+1:m_test+1]\n",
    "\n",
    "#for the case of n=0\n",
    "X_training= np.ravel(X_training)  \n",
    "X_test    = np.ravel(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0fd5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Building the Hypothesis\"\"\"\n",
    "\n",
    "def heston_pde_milstein(V0, k, theta, rho, sigma):\n",
    "    WT  = np.sqrt( 1 ) * np.random.multivariate_normal(np.array([0, 0]), np.array([[1, rho], [rho, 1]]))[1]\n",
    "    V1 = np.abs(V0+ k * (theta - V0) * 1 + sigma * np.sqrt(V0) * WT + .25 * sigma**2 * (WT**2 - 1))\n",
    "    return V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae600854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Building the Loss Function\"\"\"\n",
    "\n",
    "#The difference between real label and the predicted one to the power of 2\n",
    "#l = (heston_pde_milstein(X_training[i], r, k, theta, rho, sigma) - Y_training[i])**2\n",
    "\n",
    "m=len(X_training)  #Training set size\n",
    "# k: x[0], theta:x[1], rho:x[2], sigma:x[3]\n",
    "\n",
    "def Ls(X):\n",
    "    def heston_inner_func(i):   #calculates the predicted lable for each training sample\n",
    "        WT  = np.random.multivariate_normal(np.array([0, 0]), np.array([[1, X[2]], [X[2], 1]]))[1]\n",
    "        V1 =  np.abs(X_training[i] + X[0] * (X[0] - X_training[i]) * 1 + \n",
    "                     X[3] * np.sqrt(X_training[i]) * WT + .25 * X[3]**2 * (WT**2 - 1))\n",
    "        return V1\n",
    "    Ls = (1/m) * np.sum(np.array([(heston_inner_func(i) - Y_training[i])**2 for i in range(m)]))\n",
    "    return Ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5cf629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ERM: Empirical Risk Minimization\"\"\"\n",
    "\n",
    "result = minimize(Ls, (1,1,1,1))  #initial values should be given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ecd2991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Paramteres: [0.99999987 1.00000008 0.99999968 1.        ]\n",
      "Minimum Ls: 257.73406718244416\n"
     ]
    }
   ],
   "source": [
    "best_params = result.x\n",
    "print(\"Best Paramteres:\", best_params)\n",
    "print(\"Minimum Ls:\", result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba16ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Are we trapped inside a loval minima?!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "371890d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-02918bafe5df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#True Error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mLd\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_pred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "\"\"\"Evaluating the model on test Set\"\"\"\n",
    "\n",
    "k, theta, rho, sigma = best_params[0], best_params[1], best_params[2], best_params[3]\n",
    "Y_pred = np.array([heston_pde_milstein(X_test[i], k, theta, rho, sigma) for i in range(len(X_test))])\n",
    "Y_pred = np.ravel(Y_pred)\n",
    "\n",
    "#True Error\n",
    "Ld =  (1/len(Y_test)) * np.sum((Y_pred - Y_test)**2)\n",
    "print(Ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = np.array([heston_pde_milstein(X_training[i], k, theta, rho, sigma) for i in range(len(X_training))])\n",
    "L =  (1/m) * np.sum((Y_pred_train - Y_training)**2)\n",
    "print(L)\n",
    "\n",
    "print(Y_pred_train[:50])\n",
    "print(Y_training[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Using Neural Network for the Whole task: A Non-Physical Experiment\"\"\"\n",
    "\n",
    "#Let's, just for a momemnt, Ignore any pre_knowledge about the subject and see what happens\n",
    "\n",
    "m_training= 2500\n",
    "m_test= 500\n",
    "\n",
    "X_training=X[ :m_training  ]\n",
    "Y_training=Y[1:m_training+1]   #The labels are shifted 1 to the right since they should be tomorrow's volatility\n",
    "\n",
    "X_test=X[m_training: m_training + m_test]\n",
    "Y_test=Y[m_training+1: m_training+m_test+1]\n",
    "\n",
    "\n",
    "NN_R = MLPRegressor(hidden_layer_sizes=(100,100,100), max_iter=1000, \n",
    "                    alpha=1e-4, solver='adam', momentum=0.9,\n",
    "                    activation='relu', tol=1e-4, learning_rate_init=0.0001)\n",
    "\n",
    "NN_R.fit(X_training, Y_training)\n",
    "Y_pred = NN_R.predict(X_test)\n",
    "\n",
    "# print(\"Predicted Volatilty:\\n\", Y_pred[100:120])\n",
    "# print(\"\\nTrue Volatility:\\n\",     Y_test[100:120])\n",
    "# print(\"\\nThe score:\", NN_R.score(X_test, Y_test))\n",
    "\n",
    "NN_R = MLPRegressor(max_iter=10000, alpha=1e-4, solver='adam', momentum=0.9,\n",
    "                    activation='relu', tol=1e-4, learning_rate_init=0.0001)\n",
    "parameters = {'hidden_layer_sizes': [(10,), (20,), (40,), (20,20,),(20,20,20), (40,20,10) ]}\n",
    "\n",
    "gsc = GridSearchCV(NN_R, parameters, cv=6)\n",
    "\n",
    "gsc.fit(X_training, Y_training)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(gsc.best_params_)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Score with best parameters:\")\n",
    "print(gsc.best_score_)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"All scores on the grid:\")\n",
    "print(gsc.cv_results_.get('split0_test_score'))\n",
    "print(gsc.cv_results_.get('split1_test_score'))\n",
    "print(gsc.cv_results_.get('split2_test_score'))\n",
    "print(gsc.cv_results_.get('split3_test_score'))\n",
    "print(gsc.cv_results_.get('split4_test_score'))\n",
    "print(gsc.cv_results_.get('split5_test_score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4bdde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
